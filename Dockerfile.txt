# Multi-stage Dockerfile for Neuralangelo GUI

# Stage 1: Build frontend
FROM node:18-alpine AS frontend-builder

WORKDIR /app

COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

# Stage 2: Python backend with CUDA support
FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    git \
    wget \
    build-essential \
    cmake \
    libboost-all-dev \
    libeigen3-dev \
    libfreeimage-dev \
    libmetis-dev \
    libgoogle-glog-dev \
    libgflags-dev \
    libsqlite3-dev \
    libglew-dev \
    qtbase5-dev \
    libqt5opengl5-dev \
    libcgal-dev \
    libcgal-qt5-dev \
    colmap \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy backend requirements
COPY backend/requirements.txt /app/backend/
RUN pip3 install --no-cache-dir -r /app/backend/requirements.txt

# Install PyTorch with CUDA support
RUN pip3 install torch==2.0.1+cu118 torchvision==0.15.2+cu118 --index-url https://download.pytorch.org/whl/cu118

# Clone and install Neuralangelo
RUN git clone https://github.com/NVlabs/neuralangelo.git /app/neuralangelo
WORKDIR /app/neuralangelo
RUN pip3 install -r requirements.txt
RUN pip3 install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch

# Copy application files
WORKDIR /app
COPY backend/ /app/backend/
COPY --from=frontend-builder /app/dist /app/frontend/dist

# Create projects directory
RUN mkdir -p /app/projects

# Expose ports
EXPOSE 8000 3000

# Environment variables
ENV PYTHONUNBUFFERED=1
ENV NEURALANGELO_PATH=/app/neuralangelo
ENV COLMAP_PATH=/usr/bin/colmap

# Start script
COPY docker-entrypoint.sh /app/
RUN chmod +x /app/docker-entrypoint.sh

ENTRYPOINT ["/app/docker-entrypoint.sh"]